{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fugu_modules import Model\n",
    "def setup_plot(y_limits=None):\n",
    "    \"\"\"Set up the plot with common settings.\"\"\"\n",
    "    fig = plt.figure(figsize=(10, 5)) \n",
    "    ax = plt.gca()\n",
    "    fig.fontsize = 12\n",
    "    plt.tight_layout()\n",
    "    ax.grid(True)\n",
    "    # ax.xaxis.set_major_locator(MultipleLocator(2))\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x)}'))\n",
    "    \n",
    "    if y_limits is not None:\n",
    "        ax.set_ylim(y_limits)\n",
    "    \n",
    "    return ax\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3823356551483537\n",
      "Length of predictions:  32577\n",
      "Length of actual:  32577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "Test Mean Squared Error: 49.11817242609817\n",
      "Epoch 2/10, Loss: 1.2024289118792606\n",
      "Length of predictions:  32577\n",
      "Length of actual:  32577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "Test Mean Squared Error: 48.73335050419007\n",
      "Epoch 3/10, Loss: 1.156477730247339\n",
      "Length of predictions:  32577\n",
      "Length of actual:  32577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "Test Mean Squared Error: 48.38678218144703\n",
      "Epoch 4/10, Loss: 1.1282767129104372\n",
      "Length of predictions:  32577\n",
      "Length of actual:  32577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "Test Mean Squared Error: 47.823468724099826\n",
      "Epoch 5/10, Loss: 1.1097453044892438\n",
      "Length of predictions:  32577\n",
      "Length of actual:  32577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "Test Mean Squared Error: 47.16873196580409\n",
      "Epoch 6/10, Loss: 1.0962749358598376\n",
      "Length of predictions:  32577\n",
      "Length of actual:  32577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "Test Mean Squared Error: 46.808672050066\n",
      "Epoch 7/10, Loss: 1.086290776558325\n",
      "Length of predictions:  32577\n",
      "Length of actual:  32577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "Test Mean Squared Error: 46.23236725680695\n",
      "Epoch 8/10, Loss: 1.078271630456452\n",
      "Length of predictions:  32577\n",
      "Length of actual:  32577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "Test Mean Squared Error: 46.07767078767228\n",
      "Epoch 9/10, Loss: 1.071550462128709\n",
      "Length of predictions:  32577\n",
      "Length of actual:  32577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "Test Mean Squared Error: 46.25821275362986\n",
      "Epoch 10/10, Loss: 1.065925418281118\n",
      "Length of predictions:  32577\n",
      "Length of actual:  32577\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "Test Mean Squared Error: 45.81843018080241\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv( '../netrep_100ms.csv') # from net replica\n",
    "df2 = pd.read_csv('../oct_100ms.csv') # from puffer\n",
    "# add df2 to df\n",
    "\n",
    "# TODO: can add df and df2 together to get a combined dataset (may need to shuffle)\n",
    "# df = pd.concat([df, df2])\n",
    "\n",
    "df['in'] = df.iloc[:, :62].apply(list, axis=1) # 62 input features\n",
    "input_data = np.array(df['in'].tolist())\n",
    "output_data = np.array(df['actual'].tolist()) # 1 output feature\n",
    "\n",
    "model = Model()\n",
    "train_input, test_input, train_output, test_output = train_test_split(\n",
    "    input_data, output_data, test_size=0.05, random_state=42\n",
    ")\n",
    "\n",
    "model.train(train_input, train_output, test_input, test_output,\n",
    "            model_path='../models/combine_puffer_netrep.pt')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss: 2.5374941576143075\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       642\n",
      "           1       0.71      0.44      0.54      4681\n",
      "           2       0.42      0.37      0.40      6849\n",
      "           3       0.43      0.54      0.48      7285\n",
      "           4       0.31      0.55      0.40      3362\n",
      "           5       0.34      0.31      0.32      1676\n",
      "           6       0.26      0.01      0.01       698\n",
      "           7       0.18      0.02      0.03       384\n",
      "           8       0.00      0.00      0.00       287\n",
      "           9       0.02      0.00      0.01       302\n",
      "          10       0.06      0.01      0.02       433\n",
      "          11       0.03      0.01      0.01       562\n",
      "          12       0.03      0.01      0.01       765\n",
      "          13       0.01      0.00      0.00       675\n",
      "          14       0.00      0.00      0.00       517\n",
      "          15       0.00      0.00      0.00       453\n",
      "          16       0.00      0.00      0.00       389\n",
      "          17       0.00      0.00      0.00       366\n",
      "          18       0.00      0.00      0.00       310\n",
      "          19       0.00      0.00      0.00       219\n",
      "          20       0.33      0.97      0.49      1722\n",
      "\n",
      "    accuracy                           0.39     32577\n",
      "   macro avg       0.15      0.15      0.13     32577\n",
      "weighted avg       0.36      0.39      0.35     32577\n",
      "\n",
      "Initializing training dataset using <fugu_modules.Model object at 0x106867c10> as expert model\n",
      "Expert model score: 0.1321579545557456\n",
      "Initializing Trustee outer-loop with 2 iterations\n",
      "########## Outer-loop Iteration 0/2 ##########\n",
      "Initializing Trustee inner-loop with 2 iterations\n",
      "########## Inner-loop Iteration 0/10 ##########\n",
      "Sampling 6840 points from training dataset with (22803, 22803) entries\n",
      "Student model 0-0 trained with depth 19 and 643 leaves:\n",
      "Student model score: 0.42704572459480056\n",
      "Student model 0-0 fidelity: 0.4223529172226204\n",
      "########## Inner-loop Iteration 1/10 ##########\n",
      "Sampling 6840 points from training dataset with (24855, 24855) entries\n",
      "Student model 0-1 trained with depth 22 and 608 leaves:\n",
      "Student model score: 0.4978000899747842\n",
      "Student model 0-1 fidelity: 0.4989545891852464\n",
      "########## Inner-loop Iteration 2/10 ##########\n",
      "Sampling 6840 points from training dataset with (26907, 26907) entries\n",
      "Student model 0-2 trained with depth 25 and 616 leaves:\n",
      "Student model score: 0.45276867523360365\n",
      "Student model 0-2 fidelity: 0.47330659931173047\n",
      "########## Inner-loop Iteration 3/10 ##########\n",
      "Sampling 6840 points from training dataset with (28959, 28959) entries\n",
      "Student model 0-3 trained with depth 20 and 611 leaves:\n",
      "Student model score: 0.48533041744145516\n",
      "Student model 0-3 fidelity: 0.47013755501447424\n",
      "########## Inner-loop Iteration 4/10 ##########\n",
      "Sampling 6840 points from training dataset with (31011, 31011) entries\n",
      "Student model 0-4 trained with depth 25 and 616 leaves:\n",
      "Student model score: 0.46459023232981056\n",
      "Student model 0-4 fidelity: 0.4624874479079921\n",
      "########## Inner-loop Iteration 5/10 ##########\n",
      "Sampling 6840 points from training dataset with (33063, 33063) entries\n",
      "Student model 0-5 trained with depth 27 and 622 leaves:\n",
      "Student model score: 0.5219144423976843\n",
      "Student model 0-5 fidelity: 0.520907266904497\n",
      "########## Inner-loop Iteration 6/10 ##########\n",
      "Sampling 6840 points from training dataset with (35115, 35115) entries\n",
      "Student model 0-6 trained with depth 23 and 613 leaves:\n",
      "Student model score: 0.4990162940893034\n",
      "Student model 0-6 fidelity: 0.46966032187002593\n",
      "########## Inner-loop Iteration 7/10 ##########\n",
      "Sampling 6840 points from training dataset with (37167, 37167) entries\n",
      "Student model 0-7 trained with depth 22 and 636 leaves:\n",
      "Student model score: 0.5326337648001244\n",
      "Student model 0-7 fidelity: 0.517864205452898\n",
      "########## Inner-loop Iteration 8/10 ##########\n",
      "Sampling 6840 points from training dataset with (39219, 39219) entries\n",
      "Student model 0-8 trained with depth 20 and 615 leaves:\n",
      "Student model score: 0.5176235521913032\n",
      "Student model 0-8 fidelity: 0.502548314482241\n",
      "########## Inner-loop Iteration 9/10 ##########\n",
      "Sampling 6840 points from training dataset with (41271, 41271) entries\n",
      "Student model 0-9 trained with depth 23 and 578 leaves:\n",
      "Student model score: 0.4776958322618333\n",
      "Student model 0-9 fidelity: 0.47540024410462134\n",
      "########## Outer-loop Iteration 1/2 ##########\n",
      "Initializing Trustee inner-loop with 2 iterations\n",
      "########## Inner-loop Iteration 0/10 ##########\n",
      "Sampling 6840 points from training dataset with (43323, 43323) entries\n",
      "Student model 1-0 trained with depth 31 and 618 leaves:\n",
      "Student model score: 0.5214778834518989\n",
      "Student model 1-0 fidelity: 0.5801504444913204\n",
      "########## Inner-loop Iteration 1/10 ##########\n",
      "Sampling 6840 points from training dataset with (45375, 45375) entries\n",
      "Student model 1-1 trained with depth 27 and 618 leaves:\n",
      "Student model score: 0.4587699570618559\n",
      "Student model 1-1 fidelity: 0.4663881457492848\n",
      "########## Inner-loop Iteration 2/10 ##########\n",
      "Sampling 6840 points from training dataset with (47427, 47427) entries\n",
      "Student model 1-2 trained with depth 30 and 611 leaves:\n",
      "Student model score: 0.5119143482215716\n",
      "Student model 1-2 fidelity: 0.4953869334921103\n",
      "########## Inner-loop Iteration 3/10 ##########\n",
      "Sampling 6840 points from training dataset with (49479, 49479) entries\n",
      "Student model 1-3 trained with depth 24 and 615 leaves:\n",
      "Student model score: 0.5146193203833369\n",
      "Student model 1-3 fidelity: 0.5117614454433708\n",
      "########## Inner-loop Iteration 4/10 ##########\n",
      "Sampling 6840 points from training dataset with (51531, 51531) entries\n",
      "Student model 1-4 trained with depth 21 and 599 leaves:\n",
      "Student model score: 0.5441705104270006\n",
      "Student model 1-4 fidelity: 0.5608272995273672\n",
      "########## Inner-loop Iteration 5/10 ##########\n",
      "Sampling 6840 points from training dataset with (53583, 53583) entries\n",
      "Student model 1-5 trained with depth 22 and 605 leaves:\n",
      "Student model score: 0.48341864478451246\n",
      "Student model 1-5 fidelity: 0.5177046077988322\n",
      "########## Inner-loop Iteration 6/10 ##########\n",
      "Sampling 6840 points from training dataset with (55635, 55635) entries\n",
      "Student model 1-6 trained with depth 26 and 610 leaves:\n",
      "Student model score: 0.44405637402570247\n",
      "Student model 1-6 fidelity: 0.4550598199736234\n",
      "########## Inner-loop Iteration 7/10 ##########\n",
      "Sampling 6840 points from training dataset with (57687, 57687) entries\n",
      "Student model 1-7 trained with depth 25 and 604 leaves:\n",
      "Student model score: 0.4875693832225084\n",
      "Student model 1-7 fidelity: 0.4900383008605956\n",
      "########## Inner-loop Iteration 8/10 ##########\n",
      "Sampling 6840 points from training dataset with (59739, 59739) entries\n",
      "Student model 1-8 trained with depth 20 and 607 leaves:\n",
      "Student model score: 0.5770727741515183\n",
      "Student model 1-8 fidelity: 0.5772357479598654\n",
      "########## Inner-loop Iteration 9/10 ##########\n",
      "Sampling 6840 points from training dataset with (61791, 61791) entries\n",
      "Student model 1-9 trained with depth 22 and 589 leaves:\n",
      "Student model score: 0.5238078335766871\n",
      "Student model 1-9 fidelity: 0.49076123180175285\n",
      "Model explanation global fidelity report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.87      0.86      2927\n",
      "           2       0.80      0.78      0.79      5990\n",
      "           3       0.75      0.78      0.76      9159\n",
      "           4       0.68      0.65      0.67      5906\n",
      "           5       0.64      0.63      0.64      1530\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       0.10      0.09      0.10        33\n",
      "           8       0.24      0.50      0.32         8\n",
      "           9       0.63      0.31      0.41        62\n",
      "          10       0.52      0.42      0.46        65\n",
      "          11       0.41      0.52      0.46        92\n",
      "          12       0.41      0.48      0.44       130\n",
      "          13       0.40      0.38      0.39       152\n",
      "          14       0.52      0.57      0.55       194\n",
      "          15       0.44      0.50      0.47       204\n",
      "          16       0.31      0.29      0.30       156\n",
      "          17       0.64      0.72      0.67       555\n",
      "          18       0.18      0.20      0.19       107\n",
      "          19       0.35      0.45      0.39       237\n",
      "          20       0.96      0.94      0.95      5051\n",
      "\n",
      "    accuracy                           0.76     32577\n",
      "   macro avg       0.49      0.50      0.49     32577\n",
      "weighted avg       0.77      0.76      0.76     32577\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coltersirlin/.pyenv/versions/cs293/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/coltersirlin/.pyenv/versions/cs293/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/coltersirlin/.pyenv/versions/cs293/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/coltersirlin/.pyenv/versions/cs293/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate test set with trustee\n",
    "model.evaluate_with_trustee(test_input, test_output, \"evals/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate based on latency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    651528.000000\n",
      "mean          3.976824\n",
      "std           4.759738\n",
      "min           0.120000\n",
      "25%           0.995000\n",
      "50%           1.775000\n",
      "75%           6.312000\n",
      "max         162.436000\n",
      "Name: trans_time0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('/Users/coltersirlin/Desktop/cs293n/netrep_100ms.csv')\n",
    "print(test['trans_time0'].describe())\n",
    "test['in'] = test.iloc[:, :62].apply(list, axis=1)\n",
    "\n",
    "test_input = np.array(test['in'].tolist())\n",
    "test_output = np.array(test['actual'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coltersirlin/Desktop/cs293n/cs293-underspec/fugu_modules.py:331: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of predictions:  651528\n",
      "Length of actual:  651528\n",
      "1000\n",
      "2000\n",
      "3000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p8/8rlylt7140xcbtqrkfb_z4_h0000gn/T/ipykernel_97455/3883753019.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# you need to download this model from puffer website or use the one I put here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/coltersirlin/Desktop/cs293n/bbr-20221001-1/py-4-checkpoint-200.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../evals/OctAll_s_eval.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cs293n/cs293-underspec/fugu_modules.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, test_input, test_output, save_loc)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Mean Squared Error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# mse_loss = mean_squared_error(test_output.cpu().numpy(), predictions.cpu().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Mean Squared Error: {mse_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/cs293/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/cs293/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/cs293/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3716\u001b[0m             \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3718\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3719\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnew_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3720\u001b[0;31m             result = self._constructor_sliced(new_mgr, name=self.index[i]).__finalize__(\n\u001b[0m\u001b[1;32m   3721\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m             )\n\u001b[1;32m   3723\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs293/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;31m# e.g. from _box_col_values, skip validation of name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;31m# we are called internally, so short-circuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs293/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5920\u001b[0m         \u001b[0;31m# (note that this matches __getattr__, above).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5921\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_names_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5922\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5923\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5924\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5925\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5926\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5927\u001b[0m                 \u001b[0mexisting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "# you need to download this model from puffer website or use the one I put here\n",
    "model.load('/Users/coltersirlin/Desktop/cs293n/bbr-20221001-1/py-4-checkpoint-200.pt')\n",
    "model.evaluate(test_input, test_output, '../evals/OctAll_s_eval.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/Users/coltersirlin/Desktop/cs293n/netrep_100ms.csv')\n",
    "# test_df = pd.read_csv('test_allFields_ttpABR14_min100rtt_max4Mdelivery.csv')\n",
    "# trans_time_cols = [col for col in test_df.columns if col.startswith('trans_time')]\n",
    "# test_df[trans_time_cols] = test_df[trans_time_cols] / 1000\n",
    "\n",
    "\n",
    "print(test_df['trans_time0'].describe())\n",
    "test_df['in'] = test_df.iloc[:, :62].apply(list, axis=1)\n",
    "\n",
    "test_input = np.array(test_df['in'].tolist())\n",
    "test_output = np.array(test_df['actual'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.load('/mnt/md0/jaber/puffer_trustee/netrep_fineTune/model_6mCap.pt')\n",
    "# model.load('/mnt/md0/jaber/puffer_trustee/netrep_model_4m_100ms/corrected_model.pt')\n",
    "# model.load('/mnt/md0/vamsi995/puffer_retrain/bbr-20221001-1/py-4-checkpoint-200.pt')\n",
    "# model.load('/mnt/md0/jaber/puffer_trustee/feb_bbr-20190202-1/py-4-checkpoint-100.pt')\n",
    "# model.load('/mnt/md0/jaber/puffer_trustee/bbr-20221001-1/py-4-checkpoint-200.pt')\n",
    "# model.load('/mnt/md0/jaber/puffer_trustee/puffer_fineTune/model_6mCap.pt')\n",
    "# model.load('/mnt/md0/jaber/puffer_trustee/puffer_fineTune/combine_puffer_netrep.pt')\n",
    "model.evaluate(test_input, test_output, 'fineTune_onNetRep.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netrep = pd.read_csv('fineTune_onNetRep.csv')\n",
    "fugu = pd.read_csv('fugu22onNetRep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mse piont:\" , mean_squared_error(result[\"actual\"], result[\"point_predict\"]))\n",
    "print(\"mse prob\", mean_squared_error(result[\"actual\"], result[\"prob_predict\"]))\n",
    "\n",
    "print(\"MAPE piont:\" , mean_absolute_percentage_error(result[\"actual\"], result[\"point_predict\"]))\n",
    "print(\"MAPE prob\", mean_absolute_percentage_error(result[\"actual\"], result[\"prob_predict\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot CDF\n",
    "plt.figure(figsize=(8, 5))\n",
    "for col, label in zip([\"error_point\", \"error_prob\"], [\"Point Estimate\", \"Probabilistic\"]):\n",
    "    sorted_errors = np.sort(result[col])\n",
    "    cdf = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)\n",
    "    plt.plot(sorted_errors, cdf, label=label)\n",
    "\n",
    "plt.xlabel(\"Absolute Prediction Error\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for col, label in zip([\"error_point\", \"error_prob\"], [\"Point Estimate\", \"Probabilistic\"]):\n",
    "    sorted_errors = np.sort(result[col])\n",
    "    cdf = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)\n",
    "    plt.plot(sorted_errors, cdf, label=label)\n",
    "\n",
    "plt.xlabel(\"Prediction Error\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('netrep_on_netrep_AlexFunc.csv')\n",
    "df1 = pd.read_csv('netrep_on_netrep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read pkl file \n",
    "# import pickle\n",
    "# with open('/mnt/md0/jaber/puffer_trustee/onAndOff_4m_pfifo_latency100_4m/onAndOff_latency.pkl', 'rb') as f:\n",
    "#     df1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/md0/jaber/puffer_trustee/ttpABR_14days/train_netReplica_min100rtt_max6Mdelivery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_time0'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### with the CSV data or PKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('../netrep_100ms.csv')\n",
    "df['in'] = df.iloc[:, :62].apply(list, axis=1)\n",
    "df['trans_time2'].describe()\n",
    "\n",
    "# Convert the trans_time columns if the scale is not right, it should be in seconds not ms \n",
    "# trans_time_cols = [col for col in test_df.columns if col.startswith('trans_time')]\n",
    "# test_df[trans_time_cols] = test_df[trans_time_cols] / 1000\n",
    "\n",
    "input_data = np.array(df['in'].tolist())\n",
    "# should we use predict as train output or the actual output?\n",
    "output_data = np.array(df['actual'].tolist())\n",
    "# IMPORTANT: Change the transtime scale for input too \n",
    "\n",
    "\n",
    "model = Model()\n",
    "train_input, test_input, train_output, test_output = train_test_split(\n",
    "    input_data, output_data, test_size=0.01, random_state=42)\n",
    "model.train(train_input, train_output, test_input, test_output,\n",
    "            model_path='../netrep_100ms.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('/mnt/md0/vamsi995/puffer_retrain/data/train_netReplica_min100rtt_max4Mdelivery.csv')\n",
    "\n",
    "df['in'] = df.iloc[:, :62].apply(list, axis=1)\n",
    "\n",
    "train_input = np.array(df['in'].tolist())\n",
    "# should we use predict as train output or the actual output?\n",
    "train_output = np.array(df['actual'].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Tuning \n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv( '../netrep_100ms.csv')\n",
    "df2 = pd.read_csv('../oct_100ms.csv')\n",
    "# add df2 to df\n",
    "\n",
    "# TODO: uncomment\n",
    "# df = pd.concat([df, df2])\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "# trans_time_cols = [col for col in df.columns if col.startswith('trans_time')]\n",
    "# df[trans_time_cols] = df[trans_time_cols] / 1000\n",
    "print(df['trans_time0'].describe())\n",
    "\n",
    "df['in'] = df.iloc[:, :62].apply(list, axis=1)\n",
    "\n",
    "input_data = np.array(df['in'].tolist())\n",
    "# should we use predict as train output or the actual output?\n",
    "output_data = np.array(df['actual'].tolist())\n",
    "\n",
    "# model = Model()\n",
    "# model.load('/mnt/md0/vamsi995/puffer_retrain/train_models/fine_tune.pt')\n",
    "\n",
    "\n",
    "# print(len(processed_data[0]['in']))\n",
    "# print(len(processed_data[0]['out']))\n",
    "\n",
    "\n",
    "# model.load_model(\"/mnt/md0/vamsi995/puffer_retrain/bbr-20221001-1/cpp-4-checkpoint-200.pt\", \"/mnt/md0/vamsi995/puffer_retrain/bbr-20221001-1/cpp-meta-4-checkpoint-200.json\")\n",
    "# model = Model()\n",
    "# model.load(\"/mnt/md0/vamsi995/puffer_retrain/train_models/fine_tune_all_data.pt\")\n",
    "\n",
    "\n",
    "model = Model()\n",
    "train_input, test_input, train_output, test_output = train_test_split(\n",
    "    input_data, output_data, test_size=0.01, random_state=42\n",
    ")\n",
    "model.train(train_input, train_output, test_input, test_output,\n",
    "            model_path='../models/combine_puffer_netrep.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('netrep_on_netrep.csv')\n",
    "df2 = pd.read_csv('netrep_on_puffer.csv')\n",
    "df3 = pd.read_csv('puffer_on_puffer.csv')\n",
    "df4 = pd.read_csv('puffer_on_netrep.csv')\n",
    "df5 = pd.read_csv('fugu_on_netrep.csv')\n",
    "df6 = pd.read_csv('fugu_on_puffer.csv')\n",
    "df7 = pd.read_csv('fuguFeb_on_netrep.csv')\n",
    "df8 = pd.read_csv('fuguFeb_on_puffer.csv')\n",
    "df9 = pd.read_csv('fineTune_netrep_on_netrep.csv')\n",
    "df10 = pd.read_csv('fineTune_netrep_on_puffer.csv')\n",
    "\n",
    "# column names are trans_time0 to trans_time7 and then predict and actual time\n",
    "# columns = ['trasn_time0', 'trans_time1', 'trasn_time2','trasn_time3','trasn_time4','trasn_time5','trasn_time6', 'trasn_time7', 'predict', 'actual']\n",
    "# df1.columns = columns\n",
    "# df2.columns = columns\n",
    "# df3.columns = columns\n",
    "# df4.columns = columns\n",
    "# df5.columns = columns\n",
    "\n",
    "# # claculate the error which is the difference between the actual and the predicted time\n",
    "# df1['error'] = abs(df1['actual'] - df1['predict']) * 1000\n",
    "# df2['error'] = abs(df2['actual'] - df2['predict']) * 1000\n",
    "# df3['error'] = abs(df3['actual'] - df3['predict']) * 1000\n",
    "# df4['error'] = abs(df4['actual'] - df4['predict']) * 1000\n",
    "# df5['error'] = abs(df5['actual'] - df5['predict']) * 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['point_error'] = df1['point_error'] * 1000\n",
    "df2['point_error'] = df2['point_error'] * 1000\n",
    "df3['point_error'] = df3['point_error'] * 1000\n",
    "df4['point_error'] = df4['point_error'] * 1000\n",
    "df5['point_error'] = df5['point_error'] * 1000\n",
    "df6['point_error'] = df6['point_error'] * 1000\n",
    "df7['point_error'] = df7['point_error'] * 1000\n",
    "df8['point_error'] = df8['point_error'] * 1000\n",
    "df9['point_error'] = df9['point_error'] * 1000\n",
    "df10['point_error'] = df10['point_error'] * 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    \"Model: netReplica,  Test: netReplica\": df1,\n",
    "    # \"Model: netReplica,  Test: Puffer\": df2,\n",
    "    \"Model: Puffer,  Test: netReplica\": df4,\n",
    "    \"Model: Puffer, Test: Puffer\": df3, \n",
    "    \"Model: Fugu,  Test: netReplica\": df5,\n",
    "    # \"Model: Fugu,  Test: Puffer\": df6,\n",
    "    \"Model: FuguFeb,  Test: netReplica\": df7,\n",
    "    # \"Model: FuguFeb,  Test: Puffer\": df8,\n",
    "    \"Model: Fine Tuned with netReplica,  Test: netReplica\": df9\n",
    "    # \"Model: Fine Tuned with netReplica,  Test: Puffer\": df10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the 96th percentile of the error for all of dhet modesl\n",
    "for key, df in dfs.items():\n",
    "    print(key, df['point_error'].quantile(0.96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cdf for the error greter thatn 95th percentile\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = plt.gca()\n",
    "fig.fontsize = 12\n",
    "plt.tight_layout()\n",
    "ax.grid(True)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Error (ms)')\n",
    "ax.set_ylabel('CDF')\n",
    "for key, df in dfs.items():\n",
    "    df['point_error'].hist(cumulative=True, bins=1000, density=True, histtype='step', label=key)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cdf of error on df1 using line plot\n",
    "ax = setup_plot()\n",
    "for label, df in dfs.items():\n",
    "    sorted_errors = np.sort(df[\"prob_error\"])\n",
    "    cdf = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)\n",
    "    plt.plot(sorted_errors, cdf, label=label)\n",
    "\n",
    "plt.xlabel(\"Prediction Error (ms)\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.title(\"CDF of TTP Probabilistic Error for Different Models Tested on Different Datasets\")\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.xlim(1 , 12000)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fugu vs Netrep points\n",
    "### Find the points were fugu was doing well not the netRplica and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netrep = pd.read_csv('fineTune_netrep_on_netrep.csv')\n",
    "fugu = pd.read_csv('fugu_on_netrep.csv')\n",
    "test = pd.read_csv('/mnt/md0/vamsi995/puffer_retrain/data/test_netReplica_min100rtt_max4Mdelivery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = netrep[\"point_error\"] - fugu[\"point_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netrep better than netrep \n",
    "data = test.iloc[diff.nlargest(7).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the point_error of netrep and fugu to the data df\n",
    "data['netrep_point_error'] = netrep.iloc[diff.nlargest(7).index]['point_error'].values\n",
    "data['fugu_point_error'] = fugu.iloc[diff.nlargest(7).index]['point_error'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[trans_time_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping for netReplica outperforms fugu\n",
    "# data = data.drop(data.index[0])\n",
    "# data = data.drop(data.index[0])\n",
    "\n",
    "# Dropping for fugu outperforms netReplica\n",
    "data = data.drop(data.index[0])\n",
    "data = data.drop(data.index[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples with high and low error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_time_cols = [col for col in data.columns if col.startswith('trans_time')]\n",
    "rtt_cols = [col for col in data.columns if col.startswith('rtt')]\n",
    "delivery_cols = [col for col in data.columns if col.startswith('delivery_rate')]\n",
    "data[delivery_cols] = data[delivery_cols] * (8 * 1500)  / 1000000\n",
    "data[rtt_cols] = data[rtt_cols] * 1000\n",
    "data[trans_time_cols] = data[trans_time_cols] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to set up the plot\n",
    "# def setup_plot():\n",
    "#     fig, ax = plt.subplots(figsize=(10, 5))\n",
    "#     ax.set_title(\"Time Series Data (Chunks with Large Sigma)\")\n",
    "#     ax.set_xlabel(\"Index\")\n",
    "#     ax.set_ylabel(\"Values\")\n",
    "#     return ax\n",
    "\n",
    "# Function to plot time series\n",
    "def plot_time_series(columns_prefix, ax, label, index_range):\n",
    "    for row_index in range(data.shape[0]):  # Iterate over rows in the DataFrame\n",
    "        values = [data[f\"{columns_prefix}{i}\"].iloc[row_index] for i in index_range]\n",
    "        # add prediction error and sigma to the plot label\n",
    "        label = f\"Fugu Error: {data['fugu_point_error'].iloc[row_index]:.2f}s, NetRep Error: {data['netrep_point_error'].iloc[row_index]:.2f}s\"\n",
    "        ax.plot(index_range, values, label=f\"{row_index + 1}: {label} \")\n",
    "\n",
    "# List of metrics and their respective index ranges\n",
    "metrics = {\n",
    "    \"rtt\": range(9),\n",
    "    \"trans_time\": range(8),\n",
    "    \"cwnd\": range(9),\n",
    "    \"delivery_rate\": range(9),\n",
    "    \"size\": range(9),\n",
    "}\n",
    "\n",
    "# Loop through each metric and generate the plot\n",
    "# for metric, index_range in metrics.items():\n",
    "#     ax = setup_plot()\n",
    "#     plot_time_series(metric, ax, metric.capitalize(), index_range)\n",
    "#     ax.legend()\n",
    "#     plt.show()\n",
    "    \n",
    "ax = setup_plot()\n",
    "plot_time_series('rtt', ax, \"RTT (ms)\", range(9))\n",
    "ax.set_title(\"RTT of Past 8 Chunks (Fugo Outperforms Fine Tuned netReplica Model)\")\n",
    "ax.set_ylabel(\"RTT (ms)\")\n",
    "ax.set_xlabel(\"Chunk Number\")\n",
    "ax.legend(loc='upper left', fontsize='small')\n",
    "plt.show()\n",
    "\n",
    "ax = setup_plot()\n",
    "plot_time_series('trans_time', ax, \"Transmission Time (s)\", range(8))\n",
    "ax.set_title(\"Transmission Time of Past 8 Chunks (Fugo Outperforms Fine Tuned netReplica Model)\")\n",
    "ax.set_ylabel(\"Transmission Time (s)\")\n",
    "ax.set_xlabel(\"Chunk Number\")\n",
    "ax.legend(loc='upper left', fontsize='small')\n",
    "plt.show()\n",
    "\n",
    "ax = setup_plot()\n",
    "plot_time_series('delivery_rate', ax, \"Delivery Rate (Mbps)\", range(9))\n",
    "ax.set_title(\"Delivery Rate of Past 8 Chunks (Fugo Outperforms Fine Tuned netReplica Model)\")\n",
    "ax.set_ylabel(\"Delivery Rate (Mbps)\")\n",
    "ax.set_xlabel(\"Chunk Number\")\n",
    "ax.legend(loc='upper left', fontsize='small')\n",
    "plt.show()\n",
    "\n",
    "ax = setup_plot()\n",
    "plot_time_series('size', ax, \"Size (Bytes)\", range(9))\n",
    "ax.set_title(\"Size of Past 8 Chunks (Fugo Outperforms Fine Tuned netReplica Model)\") \n",
    "ax.set_ylabel(\"Size (Bytes)\")\n",
    "ax.set_xlabel(\"Chunk Number\")\n",
    "# position the legent on top left\n",
    "ax.legend(loc='upper left', fontsize='small')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs293",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
